{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import collections\n",
    "import scipy\n",
    "\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.neighbors import BallTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework your task will be to modify `KNNClassifier` class from your practice in class. The class with empty methods is provided below. Please, modify it to do all tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier(object):\n",
    "    \n",
    "    def __init__(self, k_neighbors=1, max_dist=1.):\n",
    "        \"\"\"\n",
    "        This is a constructor of the class. \n",
    "        Here you can define parameters (max_dist) of the class and \n",
    "        attributes, that are visible within all methods of the class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        k_neighbors : int\n",
    "            Number of neighbors used for classification.\n",
    "        max_dist : float\n",
    "            Maximum distance between an object and its neighbors.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Make this parameter visible in all methods of the class\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.max_dist = max_dist\n",
    "        \n",
    "        self.X_fit = None\n",
    "        self.y_fit = None\n",
    "                \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This method trains the KNN classifier. \n",
    "        Actualy, the KNN classifier has no training procedure.\n",
    "        It just remembers data (X, y) that will be used for predictions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "        y : numpy.array, shape = (n_objects)\n",
    "            1D array with the object labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X_fit = X\n",
    "        self.y_fit = y\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    def predict(self, X, method='standard', count_dist = False):\n",
    "        \"\"\"\n",
    "        This methods performs labels prediction for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted : numpy.array, shape = (n_objects)\n",
    "            1D array with predicted labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        # I saw the predict from seminar but I have my own idea of how it should look. Hope it's not a problem :)\n",
    "        if method == 'standard':\n",
    "            # Create an empty list of probabilities of each class\n",
    "            y_predicted_proba = np.zeros(shape=(X.shape[0], len(np.unique(self.y_fit))))\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(len(self.X_fit)):\n",
    "                    dist = np.sqrt(np.sum((self.X_fit[j] - X[i])**2))\n",
    "                    if dist <= self.max_dist:\n",
    "                        if count_dist:\n",
    "                            y_predicted_proba[i][self.y_fit[j]] += 1./dist\n",
    "                        else:\n",
    "                            y_predicted_proba[i][self.y_fit[j]] += 1\n",
    "                    \n",
    "                if y_predicted_proba[i].sum() > 0:\n",
    "                    y_predicted_proba[i] /= y_predicted_proba[i].sum()        \n",
    "                else:\n",
    "                    for j in range(len(y_predicted_proba[i])):\n",
    "                        y_predicted_proba[i][j] = 1./len(y_predicted_proba[i])\n",
    "        \n",
    "            y_predicted = np.ndarray(len(X))\n",
    "            for i in range(len(X)):\n",
    "                y_predicted[i] = np.argmax(y_predicted_proba[i])\n",
    "            \n",
    "            return y_predicted # return numpy.array\n",
    "        \n",
    "        if method == 'kd-tree':\n",
    "            \n",
    "            kd_test = KDTree(X)\n",
    "            \n",
    "            kd_fit = KDTree(self.X_fit)\n",
    "            y_res = kd_test.query_ball_tree(kd_fit, self.max_dist)\n",
    "            \n",
    "            for i in range(len(y_res)):\n",
    "                for j in range(len(y_res[i])):\n",
    "                    y_res[i][j] = self.y_fit[y_res[i][j]]\n",
    "                y_res[i] = collections.Counter(y_res[i]).most_common(1)[0][0]\n",
    "                \n",
    "            return np.array(y_res)  \n",
    "        \n",
    "        \n",
    "        if method == 'ckd-tree':\n",
    "            \n",
    "            ckd_test = cKDTree(X)\n",
    "            \n",
    "            ckd_fit = cKDTree(self.X_fit)\n",
    "            y_res = ckd_test.query_ball_tree(ckd_fit, self.max_dist)\n",
    "        \n",
    "            for i in range(len(y_res)):\n",
    "                for j in range(len(y_res[i])):\n",
    "                    y_res[i][j] = self.y_fit[y_res[i][j]]\n",
    "                y_res[i] = collections.Counter(y_res[i]).most_common(1)[0][0]\n",
    "                \n",
    "            return np.array(y_res)    \n",
    "        \n",
    "        if method == 'ball-tree':\n",
    "            \n",
    "            tree = BallTree(self.X_fit)\n",
    "            \n",
    "            y_res = tree.query_radius(X, self.max_dist)\n",
    "            \n",
    "            for i in range(len(y_res)):\n",
    "                for j in range(len(y_res[i])):\n",
    "                    y_res[i][j] = self.y_fit[y_res[i][j]]\n",
    "                y_res[i] = np.int64(collections.Counter(y_res[i]).most_common(1)[0][0])\n",
    "                \n",
    "            # return np.array(y_res) leads to unknown type and error so i need this :/    \n",
    "            y_pred = np.ndarray(len(y_res))\n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred[i] = y_res[i]\n",
    "            return y_pred\n",
    "            \n",
    "    \n",
    "    def predict_proba(self, X, count_dist=False):\n",
    "        \"\"\"\n",
    "        This methods performs prediction of probabilities of each class for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted_proba : numpy.array, shape = (n_objects, n_classes)\n",
    "            2D array with predicted probabilities of each class. \n",
    "            Example:\n",
    "                y_predicted_proba = [[0.1, 0.9],\n",
    "                                     [0.8, 0.2], \n",
    "                                     [0.0, 1.0], \n",
    "                                     ...]\n",
    "        \"\"\"\n",
    "        y_predicted_proba = np.zeros(shape=(X.shape[0], len(np.unique(self.y_fit))))\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(len(self.X_fit)):\n",
    "                dist = np.sqrt(np.sum((self.X_fit[j] - X[i])**2))\n",
    "                if dist <= self.max_dist:\n",
    "                    if count_dist:\n",
    "                        y_predicted_proba[i][self.y_fit[j]] += 1./dist\n",
    "                    else:\n",
    "                        y_predicted_proba[i][self.y_fit[j]] += 1\n",
    "                    \n",
    "            if y_predicted_proba[i].sum() > 0:\n",
    "                y_predicted_proba[i] /= y_predicted_proba[i].sum()        \n",
    "            else:\n",
    "                for j in range(len(y_predicted_proba[i])):\n",
    "                    y_predicted_proba[i][j] = 1./len(y_predicted_proba[i])\n",
    "                    \n",
    "            \n",
    "        return np.array(y_predicted_proba) # return numpy.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (1 point) <br/>\n",
    "Create a sample with N=1000 points using `sklearn.datasets.make_moons()` function from scikit-learn library. Also, set up random state in the function `random_state=42`. To open the function description use `Shift` + `Tab` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "sample = make_moons(n_samples=1000, random_state=42, noise=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (1 point) <br/>\n",
    "\n",
    "Split the sample into train and test samples using `sklearn.model_selection.train_test_split()` function from scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample[0], sample[1], random_state=42, test_size=0.2)\n",
    "\n",
    "assert y_test.shape[0] == 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (2 points) <br/>\n",
    "\n",
    "Modify class `KNNClassifier` above and implement `predict()` method that uses **max_dist** parameter to select neighbors like it's shown in the second figure (radius search). What accuracy do you have for your test sample?\n",
    "\n",
    "<img src=\"img/knn2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.77 s, sys: 10.9 ms, total: 7.78 s\n",
      "Wall time: 7.82 s\n"
     ]
    }
   ],
   "source": [
    "%time y_test_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of KNN classifier:  0.915\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (2 points) <br/>\n",
    "\n",
    "There are two algorithms [kd-tree](https://en.wikipedia.org/wiki/K-d_tree) and [ball-tree](https://en.wikipedia.org/wiki/Ball_tree) that help to find neighbors very fast. Using [scipy.spatial.KDTree](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.KDTree.html) function modify you classifier to speed up **predict** method. Please, create a new hyperparameter of the classifier (similar to k_neighbors) to be able to select algorithm of finding neighbors. Compare speed of predictions with differnet options (kd-tree, ball-tree, just numpy selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 7.99 ms, total: 1.27 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%time y_test_predict = knn.predict(X_test, method='kd-tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of KNN classifier with KDTree:  0.915\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "print(\"Test accuracy of KNN classifier with KDTree: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 ms, sys: 62 µs, total: 118 ms\n",
      "Wall time: 121 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_test_predict = knn.predict(X_test, method='ckd-tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of KNN classifier with cKDTree:  0.915\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "print(\"Test accuracy of KNN classifier with cKDTree: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 179 ms, sys: 3.4 ms, total: 183 ms\n",
      "Wall time: 199 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_test_predict = knn.predict(X_test, method='ball-tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of KNN classifier with BallTree:  0.915\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "print(\"Test accuracy of KNN classifier with BallTree: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (3 points) <br/>\n",
    "\n",
    "Now modify the **predict** method to provide prediction with neighbors weights.\n",
    "\n",
    "<img src=\"img/wv1.png\">\n",
    "\n",
    "<img src=\"img/wv2.png\">\n",
    "\n",
    "We propose you to use the following weights:\n",
    "\n",
    "$$\n",
    "w_{i} = \\frac{1}{\\rho(x, x_{i})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.14 s, sys: 3 ms, total: 7.14 s\n",
      "Wall time: 7.18 s\n"
     ]
    }
   ],
   "source": [
    "%time y_test_predict = knn.predict(X_test, count_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of KNN classifier:  0.925\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (3 points) <br/>\n",
    "\n",
    "Develop **predict_proba** method of the classifier. For each object this method returns probability that the object belong to each of the classes. \n",
    "\n",
    "For each object $x$ probability for each class is defined as:\n",
    "\n",
    "$$\n",
    "p_{c}(x) = \\frac{g_{c}(x)}{\\sum_{i=1}^{C} g_{i}(x)}\n",
    "$$\n",
    "\n",
    "where $C$ is number of classes.\n",
    "\n",
    "Then, the object has a vector of probabilities:\n",
    "\n",
    "$$\n",
    "p(x) = (p_{1}(x), p_{2}(x), ..., p_{C}(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=1)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 s, sys: 50.2 ms, total: 11.9 s\n",
      "Wall time: 12.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.19736842, 0.80263158],\n",
       "       [0.35849057, 0.64150943],\n",
       "       [0.17973856, 0.82026144],\n",
       "       [0.86187845, 0.13812155],\n",
       "       [0.10176991, 0.89823009],\n",
       "       [0.04268293, 0.95731707],\n",
       "       [0.30110497, 0.69889503],\n",
       "       [0.30790191, 0.69209809],\n",
       "       [0.01980198, 0.98019802],\n",
       "       [0.53865337, 0.46134663]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time y_test_predict_proba = knn.predict_proba(X_test)\n",
    "\n",
    "# Example of the output\n",
    "y_test_predict_proba[:10, :] # the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 74.1 ms, total: 14 s\n",
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.17016128, 0.82983872],\n",
       "       [0.45726214, 0.54273786],\n",
       "       [0.12691127, 0.87308873],\n",
       "       [0.90435303, 0.09564697],\n",
       "       [0.06629286, 0.93370714],\n",
       "       [0.02549551, 0.97450449],\n",
       "       [0.36387809, 0.63612191],\n",
       "       [0.3968332 , 0.6031668 ],\n",
       "       [0.01660806, 0.98339194],\n",
       "       [0.64129356, 0.35870644]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time y_test_predict_proba = knn.predict_proba(X_test, count_dist=True)\n",
    "\n",
    "# Example of the output\n",
    "y_test_predict_proba[:10, :] # the first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could have done something wrong (and as far as I wrote different from example 'predict' I expect this), but I felt no significant difference in time between all methods. However, they all show similar results, and counting distance in weight even improves prediction a bit. Also I suspect that it depends on sample size - it works just too fast to feel the difference..\n",
    "\n",
    "P.S. idk what timer says but as for my observation numpy works slower than other methods...\n",
    "P.P.S. i got the idea that to count time we need to put method on the same line - and it works fine! So, ckdtree and ball tree work great, kd-tree slower and pure numpy (even python) significantly slower. I think that improving my realisation could speed it up, but it will be copypaste on the one side and such experiment seems even more interesting for me..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
